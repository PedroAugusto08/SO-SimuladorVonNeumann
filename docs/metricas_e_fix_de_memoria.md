# Resumo: Ajustes de m√©tricas e corre√ß√µes de mem√≥ria

## üîé Contexto
Este documento resume as corre√ß√µes realizadas para estabilizar m√©tricas (especialmente Round-Robin) e resolver o crash de corrup√ß√£o de mem√≥ria (heap-buffer-overflow) detectado ao instrumentar as m√©tricas usando tempos simulados.

## ‚úÖ O que foi corrigido (principais itens)
  - Corrigido buffer overflow no carregador/loader: parser_json escrevia usando endere√ßos em bytes enquanto `MemoryManager` indexava por palavras; resultado: escrita fora de limite da mem√≥ria.
  - Corre√ß√£o: `MemoryManager` agora converte endere√ßos f√≠sicos (bytes) para √≠ndices de palavra (physical_address / 4) e usa esse √≠ndice para leituras/escritas tanto em `mainMemory`, `secondaryMemory` quanto no cache.
  - Arquivos alterados: `src/memory/MemoryManager.cpp`, `src/parser_json/parser_json.cpp` (logs e chamadas refatoradas).

  - PCB: adi√ß√£o de timestamps simulados: `arrival_sim_time`, `start_sim_time`, `finish_sim_time`, `total_wait_sim_time` e fun√ß√µes `enter_ready_queue_sim()` e `leave_ready_queue_sim()` para contabilizar espera em tempo simulado.
  - Convers√£o correta ciclos ‚Üí ns: criou-se helpers `cycles_to_ns` e `cycles_to_seconds` em `TimeUtils.hpp`.
  - Corre√ß√£o da coleta de m√©tricas: ao agregar tempos de turnaround/wait/response, convert√≠amos ciclos simulados para ns antes de somar e exibir em ms. Evitamos somar ciclos direto em vari√°veis que representavam nanosegundos.
  - Corre√ß√£o do c√°lculo do tempo de parede (wall time): `wall_elapsed_seconds` agora √© calculado via host clock relativo ao `simulation_start_time` (por exemplo, `cpu_time::now_ns() - simulation_start_ns`), n√£o interpretando ciclos como ns.
  - Sele√ß√£o de `elapsed_seconds` (base de tempo para throughput e CPU utilization): preferido `sim_elapsed_seconds` *quando pertinente*, mas agora escolhemos o m√°ximo entre `sim_elapsed_seconds`, `busy_based_sim_elapsed_seconds` e `wall_elapsed_seconds` para evitar spans muito pequenos que distorcem throughput.
  - Piso `min_elapsed_seconds` aumentado de 1e-6 (1us) para 1e-3 (1ms) no `SchedulerBase` (configur√°vel) para mitigar throughput artificialmente alto em situa√ß√µes onde sim span ‚âà 0.
  - Arquivos alterados: `src/cpu/TimeUtils.hpp`, `src/cpu/RoundRobinScheduler.cpp`, `src/cpu/FCFSScheduler.cpp`, `src/cpu/SJNScheduler.cpp`, `src/cpu/PriorityScheduler.cpp`, `src/cpu/SchedulerBase.hpp`, `src/cpu/PCB.hpp`.

  - Adicionado target `test-metrics-asan` no `Makefile` e execu√ß√µes ASAN para diagnosticar heap-buffer-overflow e validar aus√™ncia de corrup√ß√µes.
  - Melhoria nos logs de debug (via `SIM_LOG_LEVEL=debug`) para inspecionar `span_cycles`, `sim_elapsed_seconds`, `busy_seconds`, `elapsed_seconds_raw`, `chosen_elapsed_s`, m√©dias e throughput.
  - Arquivos alterados: `Makefile`, `test/test_metrics.cpp` (aumento de precis√£o ao imprimir tempos), logs debug em `RoundRobinScheduler.cpp` e outros.
  - Adicionado um novo pequeno bin√°rio de teste `test_sanity` que executa cargas de trabalho r√°pidas e verifica a sanidade b√°sica das m√©tricas em diferentes pol√≠ticas (limites de throughput, faixa de utiliza√ß√£o da CPU, tempos n√£o negativos). Isso est√° dispon√≠vel via `make test-sanity` e agora √© executado pelo `make test-all`.

## üêû Erros enfrentados (resumo)
- Heap-buffer-overflow no `parser_json` ao gravar instru√ß√µes/data para `mainMemory`. Rastreado at√© o `MemoryManager` tratar endere√ßos como √≠ndice de palavra/array diferente do que o parser usa.
- Throughput ridiculamente alto (e.g., 8e6 proc/s no RR): causado pelo piso `min_elapsed_seconds = 1e-6` quando `sim_elapsed_seconds` muito pequeno (span pequeno -> divis√£o por 1e-6), gerando throughput enorme.
- Tempos m√©dios (wait/turnaround) apareciam como `0.00 ms` no CSV: o c√≥digo somava ciclos simulados diretamente em vari√°veis com sufixo `ns` e ent√£o aplicava `cpu_time::ns_to_ms()`, resultando em valores muito pequenos (por exemplo 0.000078 ms) e por isso formatados como 0.00.
- Convers√µes err√¥neas: `cpu_time::ns_to_seconds(span_cycles)` apareceu em c√≥digo; isto converte `span_cycles` como se fossem nanosegundos, quando na verdade s√£o ciclos; foi corrigido usando `cycles_to_seconds()` ou convertendo corretamente.

## üß™ Testes usados para verificar e localizar os bugs
- ASAN (AddressSanitizer): `make test-metrics-asan` e execu√ß√£o `ASAN_OPTIONS=... ./bin/test_metrics` para reproduzir e localizar heap-buffer-overflow.
- Teste de m√©tricas automatizado: `test/test_metrics.cpp` ‚Äî executa as 4 pol√≠ticas (RR, FCFS, SJN, PRIORITY) em 8 workloads, gera `metricas_4cores.csv` e report `relatorio_metricas_4cores.txt`.
- Logs detalhados com `SIM_LOG_LEVEL=debug` para inspecionar nodos de execu√ß√£o, RC (Round robin) STATS DEBUG prints que mostram `span_cycles`, `sim_elapsed_seconds`, `busy_seconds` e `chosen_elapsed_s`.
- Mensagens de debug adicionais: prints no parser JSON mostrando `startAddr`, `mem_addr` e instru√ß√£o; prints nos quebras de coleta dos escalonadores (collect/urgent-collect) para identificar processos √≥rf√£os ou estados an√¥malos.

## Como reproduzir localmente (comandos)
No reposit√≥rio:

```bash
# Build e rodar com ASAN (debug memory checks)
make test-metrics-asan
ASAN_OPTIONS=allocator_release_delay_ms=0:detect_leaks=1 ./bin/test_metrics

# Ou rodar sem ASAN e com log debug (para ver os prints que diagnostiquei)
SIM_LOG_LEVEL=debug ./bin/test_metrics
```

Os artefatos gerados ficar√£o em `dados_graficos/csv/metricas_4cores.csv` e `dados_graficos/reports/relatorio_metricas_4cores.txt`.

## Principais mudan√ßas nos resultados ap√≥s corre√ß√µes
- O throughput e as m√©dias pequenas foram normalizados: o tempo m√©dio de execu√ß√£o (ms) aparece agora com precis√£o (microsegundos) e n√£o mais arredondado para zero.
- Throughput: o RR deixou de reportar `8e6` e agora reporta valores coerentes (o exemplo na execu√ß√£o atual mostrou ~1294 proc/s para RR).

## Resumo de arquivos modificados (n√£o exaustivo)
- src/memory/MemoryManager.cpp
- src/parser_json/parser_json.cpp
- src/cpu/PCB.hpp
- src/cpu/TimeUtils.hpp
- src/cpu/RoundRobinScheduler.cpp
- src/cpu/FCFSScheduler.cpp
- src/cpu/SJNScheduler.cpp
- src/cpu/PriorityScheduler.cpp
- src/cpu/SchedulerBase.hpp
- test/test_metrics.cpp
- Makefile (inclus√£o de target `test-metrics-asan`)

## Pr√≥ximos passos / tarefas pendentes (sugest√µes)
- Criar testes autom√°ticos de sanity (m√©tricas): valida√ß√£o de limites para throughput e CPU utilization, por pol√≠tica e por workload (falhar ou avisar se throughput for absurdamente alto).
 - Criar testes autom√°ticos de sanity (m√©tricas): valida√ß√£o de limites para throughput e CPU utilization, por pol√≠tica e por workload (falhar ou avisar se throughput for absurdamente alto).
 - Adicionar testes unit√°rios para `MemoryManager::write_raw` / `read` e cen√°rios de limites (endere√ßos fora do segmento, escritos n√£o alinhados, m√∫ltiplos programas carregados). Implementado como `test/test_memory_manager.cpp` e acedido via `make test-mem`.
- Refatorar ownership de `PCB` (substituir `PCB*` cru por `unique_ptr` ou `shared_ptr`) para evitar poss√≠veis double-free ou uso incorreto de ponteiros.
- Adicionar `test-metrics-asan` no CI para capturar regress√µes de mem√≥ria.
 - Adicionar `test-metrics-asan` no CI para capturar regress√µes de mem√≥ria. Implementado via GitHub Actions workflow `.github/workflows/asan_ci.yml` que executa ASAN, `test-sanity` e `test-mem`.
- Documentar que as m√©tricas no CSV fazem uso da `simulated` timebase (se dispon√≠vel), e indicar qual timebase foi escolhida (sim/wall) no relat√≥rio.

---

Se quiser, eu aplico os pr√≥ximos passos em ordem:
1. Adicionar testes sanity para m√©tricas (para cada pol√≠tica) e rodar CI.
2. Implementar os testes unit√°rios para `MemoryManager`.
3. Migrar `PCB*` ownership para `unique_ptr` em testes/harness.
4. Inserir `test-metrics-asan` na pipeline (Makefile + CI). 

Qual voc√™ prefere que eu fa√ßa agora? Se quiser, posso iniciar pelo passo 1 (m√©tricas sanity tests) e te entrego o patch + testes ajustados, e ent√£o re-executar as baterias (ASAN, debug, CSV) para validar a mudan√ßa.